{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Project - Colab Setup\n",
        "\n",
        "This notebook demonstrates how to use the modular LLM project in Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q transformers torch matplotlib scikit-learn numpy python-dateutil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Add repo root to path if needed\n",
        "sys.path.insert(0, '.')  # adjust if your module path differs\n",
        "\n",
        "from llm_tokenizers import BaseTokenizerWrapper\n",
        "from llm_models import Seq2SeqModelLoader\n",
        "\n",
        "print(\"✅ Imports ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = BaseTokenizerWrapper(\"t5-small\")\n",
        "model = Seq2SeqModelLoader(\"t5-small\")\n",
        "print(\"✅ Tokenizer and model loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding and Decoding\n",
        "Convert text to token IDs and back.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"hello, this is a sentence!\"\n",
        "encoded = tokenizer.encode(text)\n",
        "print(\"Text:\", text)\n",
        "print(\"Token IDs:\", encoded['input_ids'])\n",
        "print(\"Decoded:\", tokenizer.decode(encoded['input_ids']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward Pass (Encoder-Decoder)\n",
        "Run a single forward step with decoder starting at <pad>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp = \"translate english to german: hello, how are you?\"\n",
        "toks = tokenizer.encode(inp, return_tensors=\"pt\")\n",
        "decoder_input_ids = torch.tensor([[tokenizer.tokenizer.pad_token_id]])\n",
        "with torch.no_grad():\n",
        "    out = model(**toks, decoder_input_ids=decoder_input_ids)\n",
        "print(\"Logits shape:\", out.logits.shape)\n",
        "print(\"Keys:\", list(out.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Generation (Greedy)\n",
        "Use model.generate() to produce a translation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    gen_ids = model.generate(**toks, max_length=20)\n",
        "print(\"Generated IDs:\", gen_ids)\n",
        "print(\"Generated text:\", tokenizer.decode(gen_ids[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token Embeddings: PCA and Cosine Similarity\n",
        "Project token embeddings to 2D (PCA) and visualize pairwise cosine similarity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "add mardown cells to it and do"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
